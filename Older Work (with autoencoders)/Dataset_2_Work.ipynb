{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74ae5a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from IPython.display import clear_output\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "import skdim\n",
    "import time\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee9dc4d",
   "metadata": {},
   "source": [
    "### Import data and obtain the number of labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7096207e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data/dataset2.pkl'\n",
    "\n",
    "with open(filename, 'rb') as f:\n",
    "    data_tuples = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c81b687d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Data Points: 1000\n",
      "Class Labels: 2\n",
      "Feature Count: 150\n"
     ]
    }
   ],
   "source": [
    "print('Number of Data Points:', len(data_tuples))\n",
    "class_labels = []\n",
    "for i in range(len(data_tuples)):\n",
    "    class_labels.append(data_tuples[i][1])\n",
    "\n",
    "print('Class Labels:', len(set(class_labels)))\n",
    "print('Feature Count:', len(data_tuples[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813f7b26",
   "metadata": {},
   "source": [
    "### Perform Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4504818a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame([i[0] for i in data_tuples])\n",
    "data = (data - np.min(data)) / (np.max(data) - np.min(data))\n",
    "labels = pd.DataFrame([i[1] for i in data_tuples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "343f8856-e790-43b0-8a1d-74112c4fd287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.18147540092468262 seconds ---\n",
      "26.26175147302017\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "\n",
    "#estimate local intrinsic dimension (dimension in k-nearest-neighborhoods around each point):\n",
    "est = skdim.id.MOM().fit(data,\n",
    "                              n_neighbors = 50,\n",
    "                              n_jobs = -1,)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "#get estimated intrinsic dimension\n",
    "print(np.mean(est.dimension_pw_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccbfa20-4939-4d4a-819e-c5c5add8377f",
   "metadata": {},
   "source": [
    "### Perform Dimensionality Reduction (Autoencoder Testing) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d113d0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42, stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99788269",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_tr = tf.data.Dataset.from_tensor_slices(X_train)\n",
    "ds_te = tf.data.Dataset.from_tensor_slices(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4605e98-cc03-4cb9-adad-13ff4a0cc562",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coefficient(low, id, high):\n",
    "    return (high-id)/(high-low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1c71803",
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6d16254",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of 20: \n",
      "\t(trn) 0.007567799650132656 \t(val) 0.007547427900135517\n",
      "\n",
      "Result of 25: \n",
      "\t(trn) 0.008026986382901669 \t(val) 0.008076051250100136\n",
      "\n",
      "Result of 30: \n",
      "\t(trn) 0.007932948879897594 \t(val) 0.007963971234858036\n",
      "\n",
      "Coefficient: -0.2690716809014891\n",
      "\n",
      "Elbow Calculation: -33.31723296061956\n",
      "\n",
      "Trn-Val Difference of ID: 4.9064867198467255e-05\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(42) # extra code â€“ ensures reproducibility on CPU\n",
    "\n",
    "radius = 5\n",
    "\n",
    "shape = len(data_tuples[0][0])\n",
    "\n",
    "input = tf.keras.layers.Input(shape=(shape,))\n",
    "\n",
    "latent_minus = tf.keras.layers.Dense(max(ID-radius, 1), activation=\"relu\")(input)\n",
    "latent_id = tf.keras.layers.Dense(ID, activation=\"relu\")(input)\n",
    "latent_plus = tf.keras.layers.Dense(ID+radius, activation=\"relu\")(input)\n",
    "\n",
    "output_minus = tf.keras.layers.Dense(shape)(latent_minus)\n",
    "output_id = tf.keras.layers.Dense(shape)(latent_id)\n",
    "output_plus = tf.keras.layers.Dense(shape)(latent_plus)\n",
    "\n",
    "model = tf.keras.Model(inputs=[input],\n",
    "                       outputs=[output_minus, output_id, output_plus])\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"nadam\",\n",
    "              metrics=[\"RootMeanSquaredError\"])\n",
    "history = model.fit(X_train, X_train, epochs=10,\n",
    "                         validation_data=(X_test, X_test))\n",
    "\n",
    "results = []\n",
    "\n",
    "for i in history.history:\n",
    "    results.append((i, history.history[i][-1]))\n",
    "\n",
    "# 'ID - radius' validation loss\n",
    "(ID-radius), results[8][1]\n",
    "\n",
    "clear_output(wait=True)\n",
    "\n",
    "print(\"Result of {}: \\n\\t(trn) {} \\t(val) {}\\n\".format(max(ID-radius, 1), results[1][1], results[8][1]))\n",
    "print(\"Result of {}: \\n\\t(trn) {} \\t(val) {}\\n\".format(ID, results[2][1], results[9][1]))\n",
    "print(\"Result of {}: \\n\\t(trn) {} \\t(val) {}\\n\".format(ID+radius, results[3][1], results[10][1]))\n",
    "\n",
    "c = coefficient(results[8][1], results[9][1], results[10][1])\n",
    "\n",
    "print(\"Coefficient: {}\\n\".format(c))\n",
    "print(\"Elbow Calculation: {}\\n\".format(c/results[9][1]))\n",
    "print(\"Trn-Val Difference of ID: {}\".format(abs(results[9][1]-results[2][1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be55691-92a1-4ff7-acf4-9a8f4d5d399d",
   "metadata": {},
   "source": [
    "### Classifier(s) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "19e0be82",
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6b5b8c3a-209f-4613-9abc-3d2295ea0ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.36318373680114746 seconds ---\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(shape,)),\n",
    "    tf.keras.layers.Dense(ID, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10)\n",
    "\n",
    "clear_output(wait=True)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dc5dd64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 726us/step - loss: 0.2911 - accuracy: 1.0000\n",
      "7/7 [==============================] - 0s 582us/step\n",
      "7/7 [==============================] - 0s 498us/step\n",
      "\n",
      "Test accuracy: 1.0\n",
      "\n",
      "Test F1 (macro): 1.0\n",
      "\n",
      "Test F1 (weighted): 1.0\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test,  y_test)\n",
    "f1_w = f1_score(y_test, [0 if x < 0 else 1 for x in model.predict(X_test)], average='weighted')\n",
    "f1_m = f1_score(y_test, [0 if x < 0 else 1 for x in model.predict(X_test)], average='macro')\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)\n",
    "print('\\nTest F1 (macro):', f1_m)\n",
    "print('\\nTest F1 (weighted):', f1_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83ac25f-8fc9-42bc-94f5-e4a82e1ecf13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
